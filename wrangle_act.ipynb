{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle & Analyze WeRateDogs Data\n",
    "\n",
    "<hr>\n",
    "\n",
    "Real-world data rarely comes clean. Using Python and its libraries, I will gather data from a variety of sources and in a variety of formats, assess its quality and tidiness, then clean it. This is called data wrangling. I will document my wrangling efforts in a Jupyter Notebook, plus showcase them through analyses and visualizations using Python.\n",
    "\n",
    "The dataset that I will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"img/dog-rates-social.jpg\" width=\"600\">\n",
    "</p>\n",
    "\n",
    "The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. One column the archive does contain though: each tweet's text, which I used to extract rating, dog name, and dog \"stage\" (i.e. doggo, floofer, pupper, and puppo) to make this Twitter archive \"enhanced.\" Of the 5000+ tweets, I have filtered for tweets with ratings only (there are 2356).\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"img/data.png\" width=\"1300\">\n",
    "</p>\n",
    "\n",
    "Retweet count and favorite count are two of the notable column omissions. Fortunately, this additional data can be gathered from Twitter's API, which I will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_distributor_init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6760768f1008>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import libs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\dand\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;31m# Allow distributors to run custom init code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_distributor_init'"
     ]
    }
   ],
   "source": [
    "# import libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "# pandas settings\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "Gather data from various sources and a variety of file formats.\n",
    "\n",
    "<hr>\n",
    "\n",
    "* [Enhanced Twitter Archive](#Enhanced-Twitter-Archive)  \n",
    "* [Image Predictions File](#Image-Predictions-File)  \n",
    "* [Twitter API File](#Twitter-API-File)\n",
    "\n",
    "### Enhanced Twitter Archive\n",
    "\n",
    "This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load twitter archive\n",
    "twitter_arch = pd.read_csv(\"data/twitter-archive-enhanced.csv\")\n",
    "# use tweet id column as index\n",
    "twitter_arch.set_index(\"tweet_id\", inplace = True)\n",
    "# display few lines\n",
    "twitter_arch.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Predictions File\n",
    "\n",
    "This file contains top three predictions of dog breed for each dog image from the WeRateDogs archive. Table contains the top three predictions, tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file with the image predictions\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "with open('data/image-predictions.tsv' , 'wb') as file:\n",
    "    predictions = requests.get(url)\n",
    "    file.write(predictions.content)\n",
    "\n",
    "# load image predictions\n",
    "image_pred = pd.read_csv('data/image-predictions.tsv', sep = '\\t')\n",
    "# use tweet id column as index\n",
    "image_pred.set_index(\"tweet_id\", inplace = True)\n",
    "# display few lines\n",
    "image_pred.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter API File\n",
    "\n",
    "Retweet count and favorite count are two of the notable column omissions of Twitter data archive. Fortunately, this additional data can be gathered from Twitter's API. Twitter API file contains tweet id, favorite count and retweet count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load twitter API data\n",
    "with open('data/tweet-json.txt') as f:\n",
    "    twitter_api = pd.DataFrame((json.loads(line) for line in f), columns = ['id', 'favorite_count', 'retweet_count'])\n",
    "\n",
    "# change column names\n",
    "twitter_api.columns = ['tweet_id', 'favorites', 'retweets']\n",
    "# use tweet id column as index\n",
    "twitter_api.set_index('tweet_id', inplace = True)\n",
    "# display few lines\n",
    "twitter_api.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data\n",
    "\n",
    "Assess data visually and programmatically for quality and tidiness issues using pandas.\n",
    "\n",
    "<hr>\n",
    "\n",
    "* [Twitter Archive Data](#Twitter-Archive-Data)  \n",
    "* [Image Predictions](#Image-Predictions)  \n",
    "* [Twitter API Data](#Twitter-API-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Archive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample of data\n",
    "twitter_arch.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pint a summary of a DataFrame\n",
    "twitter_arch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if ids are unique\n",
    "twitter_arch.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of replies\n",
    "np.isfinite(twitter_arch.in_reply_to_status_id).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check values in sources\n",
    "twitter_arch.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check quality of text\n",
    "twitter_arch.text.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of retweets\n",
    "np.isfinite(twitter_arch.retweeted_status_id).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check expanded urls\n",
    "twitter_arch[~twitter_arch.expanded_urls.str.startswith(('https://twitter.com','http://twitter.com', 'https://vine.co'), na=False)].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for two or more urls in the expanded urls\n",
    "twitter_arch[twitter_arch.expanded_urls.str.contains(',', na=False)].expanded_urls.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rating denominator\n",
    "twitter_arch.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rating numerator\n",
    "twitter_arch.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any float ratings in the text column\n",
    "twitter_arch[twitter_arch.text.str.contains(r'\\d+\\.\\d+\\/\\d+')][['text','rating_denominator', 'rating_numerator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check name of dog\n",
    "twitter_arch.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for stop words in dog name\n",
    "# https://stackoverflow.com/a/5486535/7382214\n",
    "\n",
    "stop_words = set(get_stop_words('en'))\n",
    "\n",
    "count=0\n",
    "for word in twitter_arch.name:\n",
    "    if word.lower() in stop_words:\n",
    "        count += 1\n",
    "print('Rows with stop words:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if gods have more than one category assigned\n",
    "categories = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "\n",
    "for category in categories:\n",
    "    twitter_arch[category] = twitter_arch[category].apply(lambda x: 0 if x=='None' else 1)\n",
    "\n",
    "twitter_arch['number_categories'] = twitter_arch.iloc[:,[12,13,14,15]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dogs categories\n",
    "twitter_arch['number_categories'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality & Tidiness Issues\n",
    "\n",
    "- in_reply_to_status_id, in_reply_to_user_id have an incorrect datatype - is a float, should be int;\n",
    "- some of the gathered tweets are replies;\n",
    "- the timestamp has an incorrect datatype - is an object, should be DateTime;\n",
    "- source is an HTML element - it's text should be extracted;\n",
    "- some rows in the text column begin from 'RT @dog_rates:';\n",
    "- some rows in the text column have leading and/or trailing whitespace;\n",
    "- some of the gathered tweets are retweets;\n",
    "- retweeted_status_id, retweeted_status_user_id have an incorrect datatype - is a float, should be int;\n",
    "- the retweeted timestamp has an incorrect datatype - is an object, should be DateTime;\n",
    "- we have 59 missing expanded urls;\n",
    "- we have 639 expanded urls which contain more than one url address;\n",
    "- denominator of some ratings is not 10;\n",
    "- numerator of some ratings is almost always greater than 10;\n",
    "- float ratings have been incorrectly read from the text of tweet;\n",
    "- 'None' in the name should be convert to NaN;\n",
    "- we have stop words in the name column;\n",
    "- dog 'stage' classification (doggo, floofer, pupper or puppo) should be one column;\n",
    "- some dogs have more than one category assigned;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample of data\n",
    "image_pred.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pint a summary of a DataFrame\n",
    "image_pred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if ids are unique\n",
    "image_pred.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check jpg_url\n",
    "image_pred[~image_pred.jpg_url.str.endswith(('.jpg', '.png'), na=False)].jpg_url.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check image number\n",
    "image_pred.img_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check 1st prediction\n",
    "image_pred.p1.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dog predictions\n",
    "image_pred.p1_dog.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality & Tidiness Issues\n",
    "\n",
    "- the dataset has 2075 entries, while twitter archive dataset has 2356 entries;\n",
    "- column names are confusing and do not give much information about the content;\n",
    "- dog breeds contain underscores, and have different case formatting;\n",
    "- only 2075 images have been classified as dog images for top prediction;\n",
    "- dataset should be merged with the twitter archive dataset;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter API Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample of data\n",
    "twitter_api.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pint a summary of a DataFrame\n",
    "twitter_api.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if ids are unique\n",
    "twitter_arch.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality & Tidiness Issues\n",
    "\n",
    "- twitter archive dataset has 2356 entries, while twitter API data has 2354;\n",
    "- dataset should be merged with the twitter archive dataset;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "Using pandas, clean the quality and tidiness issues identified in the [Assessing Data](#Assessing-Data) section.\n",
    "\n",
    "<hr>\n",
    "\n",
    "* [Twitter Archive Data](#Twitter-Archive-Data)  \n",
    "* [Image Predictions](#Image-Predictions)  \n",
    "* [Twitter API Data](#Twitter-API-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Data\n",
    "\n",
    "Analyze and visualize data using matplotlib.\n",
    "\n",
    "<hr>\n",
    "\n",
    "* [Twitter Archive Data](#Twitter-Archive-Data)  \n",
    "* [Image Predictions](#Image-Predictions)  \n",
    "* [Twitter API Data](#Twitter-API-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
